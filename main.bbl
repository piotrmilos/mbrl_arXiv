\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Azizzadenesheli et~al.(2018)Azizzadenesheli, Yang, Liu, Brunskill,
  Lipton, and Anandkumar]{gats}
Azizzadenesheli, K., Yang, B., Liu, W., Brunskill, E., Lipton, Z.~C., and
  Anandkumar, A.
\newblock Sample-efficient deep {RL} with generative adversarial tree search.
\newblock \emph{CoRR}, abs/1806.05780, 2018.
\newblock URL \url{http://arxiv.org/abs/1806.05780}.

\bibitem[Babaeizadeh et~al.(2016)Babaeizadeh, Frosio, Tyree, Clemons, and
  Kautz]{ga3c}
Babaeizadeh, M., Frosio, I., Tyree, S., Clemons, J., and Kautz, J.
\newblock Reinforcement learning through asynchronous advantage actor-critic on
  a gpu.
\newblock \emph{arXiv preprint arXiv:1611.06256}, 2016.

\bibitem[Babaeizadeh et~al.(2017)Babaeizadeh, Finn, Erhan, Campbell, and
  Levine]{sv2p}
Babaeizadeh, M., Finn, C., Erhan, D., Campbell, R.~H., and Levine, S.
\newblock Stochastic variational video prediction.
\newblock \emph{ICLR}, 2017.

\bibitem[Bellemare et~al.(2015)Bellemare, Naddaf, Veness, and Bowling]{ale}
Bellemare, M.~G., Naddaf, Y., Veness, J., and Bowling, M.
\newblock The arcade learning environment: An evaluation platform for general
  agents (extended abstract).
\newblock In \emph{Proceedings of the Twenty-Fourth International Joint
  Conference on Artificial Intelligence, {IJCAI}}, pp.\  4148--4152, 2015.

\bibitem[Bengio et~al.(2015)Bengio, Vinyals, Jaitly, and Shazeer]{BengioVJS15}
Bengio, S., Vinyals, O., Jaitly, N., and Shazeer, N.
\newblock Scheduled sampling for sequence prediction with recurrent neural
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems 28: Annual
  Conference on Neural Information Processing Systems 2015, December 7-12,
  2015, Montreal, Quebec, Canada}, pp.\  1171--1179, 2015.

\bibitem[Buesing et~al.(2018)Buesing, Weber, Zwols, Racani{\`{e}}re, Guez,
  Lespiau, and Heess]{woulda_coulda_shoulda}
Buesing, L., Weber, T., Zwols, Y., Racani{\`{e}}re, S., Guez, A., Lespiau, J.,
  and Heess, N.
\newblock Woulda, coulda, shoulda: Counterfactually-guided policy search.
\newblock \emph{CoRR}, abs/1811.06272, 2018.

\bibitem[Castro et~al.(2018)Castro, Moitra, Gelada, Kumar, and
  Bellemare]{DBLP:journals/corr/abs-1812-06110}
Castro, P.~S., Moitra, S., Gelada, C., Kumar, S., and Bellemare, M.~G.
\newblock Dopamine: {A} research framework for deep reinforcement learning.
\newblock \emph{CoRR}, abs/1812.06110, 2018.

\bibitem[Chiappa et~al.(2017)Chiappa, Racani{\`{e}}re, Wierstra, and
  Mohamed]{recurrent}
Chiappa, S., Racani{\`{e}}re, S., Wierstra, D., and Mohamed, S.
\newblock Recurrent environment simulators.
\newblock \emph{CoRR}, abs/1704.02254, 2017.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{Chua18}
Chua, K., Calandra, R., McAllister, R., and Levine, S.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4759--4770, 2018.

\bibitem[Deisenroth et~al.(2013)Deisenroth, Neumann, and Peters]{deisenroth}
Deisenroth, M.~P., Neumann, G., and Peters, J.
\newblock A survey on policy search for robotics.
\newblock \emph{Foundations and Trends in Robotics}, 2\penalty0 (1-2), 2013.

\bibitem[Ebert et~al.(2017)Ebert, Finn, Lee, and Levine]{ebert}
Ebert, F., Finn, C., Lee, A.~X., and Levine, S.
\newblock Self-supervised visual planning with temporal skip connections.
\newblock \emph{CoRR}, abs/1710.05268, 2017.

\bibitem[Ebert et~al.(2018)Ebert, Finn, Dasari, Xie, Lee, and
  Levine]{ebert2018visual}
Ebert, F., Finn, C., Dasari, S., Xie, A., Lee, A., and Levine, S.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock \emph{arXiv preprint arXiv:1812.00568}, 2018.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, Legg, and Kavukcuoglu]{vtrace}
Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron,
  Y., Firoiu, V., Harley, T., Dunning, I., Legg, S., and Kavukcuoglu, K.
\newblock {IMPALA:} scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML}}, pp.\  1406--1415, 2018.

\bibitem[Feinberg et~al.(2018)Feinberg, Wan, Stoica, Jordan, Gonzalez, and
  Levine]{model_based_value_estimation}
Feinberg, V., Wan, A., Stoica, I., Jordan, M.~I., Gonzalez, J.~E., and Levine,
  S.
\newblock Model-based value estimation for efficient model-free reinforcement
  learning.
\newblock \emph{CoRR}, abs/1803.00101, 2018.

\bibitem[Finn \& Levine(2016)Finn and Levine]{finn2016}
Finn, C. and Levine, S.
\newblock Deep visual foresight for planning robot motion.
\newblock \emph{CoRR}, abs/1610.00696, 2016.

\bibitem[Finn et~al.(2016)Finn, Tan, Duan, Darrell, Levine, and
  Abbeel]{deep_spatial}
Finn, C., Tan, X.~Y., Duan, Y., Darrell, T., Levine, S., and Abbeel, P.
\newblock Deep spatial autoencoders for visuomotor learning.
\newblock In \emph{{IEEE} International Conference on Robotics and Automation,
  {ICRA}}, pp.\  512--519, 2016.

\bibitem[Ha \& Schmidhuber(2018)Ha and Schmidhuber]{world_models}
Ha, D. and Schmidhuber, J.
\newblock World models.
\newblock \emph{CoRR}, abs/1803.10122, 2018.

\bibitem[Hafner et~al.(2018)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner}
Hafner, D., Lillicrap, T.~P., Fischer, I., Villegas, R., Ha, D., Lee, H., and
  Davidson, J.
\newblock Learning latent dynamics for planning from pixels.
\newblock \emph{CoRR}, abs/1811.04551, 2018.

\bibitem[Heess et~al.(2015)Heess, Wayne, Silver, Lillicrap, Tassa, and
  Erez]{stochastic_value_gradients}
Heess, N., Wayne, G., Silver, D., Lillicrap, T.~P., Tassa, Y., and Erez, T.
\newblock Learning continuous control policies by stochastic value gradients.
\newblock \emph{CoRR}, abs/1510.09142, 2015.

\bibitem[Hessel et~al.(2017)Hessel, Modayil, van Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{rainbow}
Hessel, M., Modayil, J., van Hasselt, H., Schaul, T., Ostrovski, G., Dabney,
  W., Horgan, D., Piot, B., Azar, M.~G., and Silver, D.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock \emph{CoRR}, abs/1710.02298, 2017.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Holland et~al.(2018)Holland, Talvitie, and Bowling]{dyna_dqn}
Holland, G.~Z., Talvitie, E., and Bowling, M.
\newblock The effect of planning shape on dyna-style planning in
  high-dimensional state spaces.
\newblock \emph{CoRR}, abs/1806.01825, 2018.
\newblock URL \url{http://arxiv.org/abs/1806.01825}.

\bibitem[Kaiser \& Bengio(2018)Kaiser and Bengio]{auto_discrete}
Kaiser, L. and Bengio, S.
\newblock Discrete autoencoders for sequence models.
\newblock \emph{CoRR}, abs/1801.09797, 2018.

\bibitem[Kalweit \& Boedecker(2017)Kalweit and
  Boedecker]{uncertainty_driven_imagination}
Kalweit, G. and Boedecker, J.
\newblock Uncertainty-driven imagination for continuous deep reinforcement
  learning.
\newblock In Levine, S., Vanhoucke, V., and Goldberg, K. (eds.),
  \emph{Proceedings of the 1st Annual Conference on Robot Learning}, volume~78
  of \emph{Proceedings of Machine Learning Research}, pp.\  195--206. PMLR,
  13--15 Nov 2017.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kurutach et~al.(2018)Kurutach, Clavera, Duan, Tamar, and
  Abbeel]{trpo_ensemble}
Kurutach, T., Clavera, I., Duan, Y., Tamar, A., and Abbeel, P.
\newblock Model-ensemble trust-region policy optimization.
\newblock \emph{CoRR}, abs/1802.10592, 2018.

\bibitem[Leibfried et~al.(2016)Leibfried, Kushman, and
  Hofmann]{video_reward_prediction}
Leibfried, F., Kushman, N., and Hofmann, K.
\newblock A deep learning approach for joint video frame and reward prediction
  in {A}tari games.
\newblock \emph{CoRR}, abs/1611.07078, 2016.

\bibitem[Machado et~al.(2017)Machado, Bellemare, Talvitie, Veness, Hausknecht,
  and Bowling]{ale2}
Machado, M.~C., Bellemare, M.~G., Talvitie, E., Veness, J., Hausknecht, M.~J.,
  and Bowling, M.
\newblock Revisiting the arcade learning environment: Evaluation protocols and
  open problems for general agents.
\newblock \emph{CoRR}, abs/1709.06009, 2017.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{dqn}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.~A.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{CoRR}, abs/1312.5602, 2013.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{dqn2}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M.~A., Fidjeland, A., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{a3c}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T.~P., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{Proceedings of the 33nd International Conference on Machine
  Learning, {ICML}}, pp.\  1928--1937, 2016.

\bibitem[Oh et~al.(2015)Oh, Guo, Lee, Lewis, and Singh]{video_prediction}
Oh, J., Guo, X., Lee, H., Lewis, R.~L., and Singh, S.~P.
\newblock Action-conditional video prediction using deep networks in atari
  games.
\newblock In \emph{{NIPS}}, pp.\  2863--2871, 2015.

\bibitem[Oh et~al.(2017)Oh, Singh, and Lee]{vpn}
Oh, J., Singh, S., and Lee, H.
\newblock Value prediction network.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 30}, pp.\  6118--6128. Curran Associates,
  Inc., 2017.

\bibitem[Paxton et~al.(2018)Paxton, Barnoy, Katyal, Arora, and Hager]{paxton}
Paxton, C., Barnoy, Y., Katyal, K.~D., Arora, R., and Hager, G.~D.
\newblock Visual robot task planning.
\newblock \emph{CoRR}, abs/1804.00062, 2018.

\bibitem[Piergiovanni et~al.(2018)Piergiovanni, Wu, and Ryoo]{piergiovanni}
Piergiovanni, A.~J., Wu, A., and Ryoo, M.~S.
\newblock Learning real-world robot policies by dreaming.
\newblock \emph{CoRR}, abs/1805.07813, 2018.

\bibitem[Pohlen et~al.(2018)Pohlen, Piot, Hester, Azar, Horgan, Budden,
  Barth{-}Maron, van Hasselt, Quan, Vecer{\'{\i}}k, Hessel, Munos, and
  Pietquin]{Pohlenetal2018}
Pohlen, T., Piot, B., Hester, T., Azar, M.~G., Horgan, D., Budden, D.,
  Barth{-}Maron, G., van Hasselt, H., Quan, J., Vecer{\'{\i}}k, M., Hessel, M.,
  Munos, R., and Pietquin, O.
\newblock Observe and look further: Achieving consistent performance on atari.
\newblock \emph{CoRR}, abs/1805.11593, 2018.

\bibitem[Rybkin et~al.(2018)Rybkin, Pertsch, Jaegle, Derpanis, and
  Daniilidis]{rybkin-pertsch}
Rybkin, O., Pertsch, K., Jaegle, A., Derpanis, K.~G., and Daniilidis, K.
\newblock Unsupervised learning of sensorimotor affordances by stochastic
  future prediction.
\newblock \emph{CoRR}, abs/1806.09655, 2018.

\bibitem[Schmidhuber(2010)]{schmidhuber_formal_theory}
Schmidhuber, J.
\newblock Formal theory of creativity, fun, and intrinsic motivation
  {(1990-2010)}.
\newblock \emph{{IEEE} Trans. Autonomous Mental Development}, 2\penalty0
  (3):\penalty0 230--247, 2010.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{ppo}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{CoRR}, abs/1707.06347, 2017.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Sutton(1991)]{dyna}
Sutton, R.~S.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock \emph{SIGART Bull.}, 2\penalty0 (4):\penalty0 160--163, July 1991.

\bibitem[Sutton \& Barto(2017)Sutton and Barto]{sutton_barto_2017}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement learning - an introduction, 2nd edition (work in
  progress)}.
\newblock Adaptive computation and machine learning. {MIT} Press, 2017.

\bibitem[Tsividis et~al.(2017)Tsividis, Pouncy, Xu, Tenenbaum, and
  Gershman]{human_atari_minutes}
Tsividis, P., Pouncy, T., Xu, J.~L., Tenenbaum, J.~B., and Gershman, S.~J.
\newblock Human learning in atari.
\newblock In \emph{2017 {AAAI} Spring Symposia, Stanford University, Palo Alto,
  California, USA, March 27-29, 2017}, 2017.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Vinyals, and
  Kavukcuoglu]{neural_discrete}
van~den Oord, A., Vinyals, O., and Kavukcuoglu, K.
\newblock Neural discrete representation learning.
\newblock \emph{CoRR}, abs/1711.00937, 2017.

\bibitem[Venkatraman et~al.(2016)Venkatraman, Capobianco, Pinto, Hebert, Nardi,
  and Bagnell]{venkatraman}
Venkatraman, A., Capobianco, R., Pinto, L., Hebert, M., Nardi, D., and Bagnell,
  J.~A.
\newblock Improved learning of dynamics models for control.
\newblock In \emph{International Symposium on Experimental Robotics, {ISER}
  2016, Tokyo, Japan, October 3-6, 2016.}, pp.\  703--713, 2016.
\newblock \doi{10.1007/978-3-319-50115-4\_61}.
\newblock URL \url{https://doi.org/10.1007/978-3-319-50115-4\_61}.

\bibitem[Watter et~al.(2015)Watter, Springenberg, Boedecker, and
  Riedmiller]{embed_to_control}
Watter, M., Springenberg, J.~T., Boedecker, J., and Riedmiller, M.~A.
\newblock Embed to control: {A} locally linear latent dynamics model for
  control from raw images.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2746--2754, 2015.

\bibitem[Wu et~al.(2017)Wu, Mansimov, Liao, Grosse, and Ba]{acktr}
Wu, Y., Mansimov, E., Liao, S., Grosse, R.~B., and Ba, J.
\newblock Scalable trust-region method for deep reinforcement learning using
  kronecker-factored approximation.
\newblock \emph{CoRR}, abs/1708.05144, 2017.

\end{thebibliography}
